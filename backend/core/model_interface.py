"""Model Interface - Connects to local and external AI models"""
from typing import Dict, List, Optional
import os


class ModelInterface:
    """Interface for connecting to various AI models (local/cloud)"""
    
    def __init__(self):
        self.available_models = {}
        self.active_model = None
        self.model_requests = []  # Track requests for new models
        self._detect_available_models()
    
    def _detect_available_models(self):
        """Detect what models are available (local or via API keys)"""
        # Check for common model environment variables
        if os.getenv('OPENAI_API_KEY'):
            self.available_models['openai'] = {
                'type': 'api',
                'status': 'available'
            }
        
        if os.getenv('ANTHROPIC_API_KEY'):
            self.available_models['anthropic'] = {
                'type': 'api',
                'status': 'available'
            }
        
        # Check for local model paths
        local_model_path = os.getenv('LOCAL_MODEL_PATH')
        if local_model_path and os.path.exists(local_model_path):
            self.available_models['local'] = {
                'type': 'local',
                'path': local_model_path,
                'status': 'available'
            }
        
        # Set default active model if any available
        if self.available_models and not self.active_model:
            self.active_model = list(self.available_models.keys())[0]
    
    def generate_response(self, context: dict) -> str:
        """Generate response using active model"""
        
        if not self.active_model or self.active_model not in self.available_models:
            # No model available - return explanatory message
            return self._generate_no_model_response(context)
        
        # In production, this would call actual model API
        # For now, return intelligent placeholder
        user_message = context.get('user_message', '')
        confidence = context.get('system_confidence', 0.5)
        
        # Simulate thoughtful response based on system state
        if confidence > 0.7:
            response = f"Based on our interaction history and understanding patterns, regarding '{user_message}': [This is where the autonomous AI would generate a deeply personalized response using {self.active_model} model]"
        else:
            response = f"I'm processing '{user_message}' through my multi-brain analysis system. [Response would be generated by {self.active_model} model integrated with memory and theories]"
        
        return response
    
    def _generate_no_model_response(self, context: dict) -> str:
        """Generate response when no AI model is available"""
        return (
            "ðŸ§  Psyche-Lab Intelligence System Active\n\n"
            f"Your message: {context.get('user_message', '')}\n\n"
            "Multi-brain analysis complete. However, no AI language model is currently connected. "
            "The system requires access to an AI model to generate natural language responses.\n\n"
            "Please provide:\n"
            "- OpenAI API key (set OPENAI_API_KEY environment variable), or\n"
            "- Anthropic API key (set ANTHROPIC_API_KEY), or\n"
            "- Local model path (set LOCAL_MODEL_PATH)\n\n"
            f"System confidence: {context.get('system_confidence', 0.5):.2f} | "
            f"Memories active: {len(context.get('relevant_memories', []))} | "
            f"Theories tested: {len(context.get('active_theories', []))}"
        )
    
    def request_model(self, model_type: str, reason: str) -> dict:
        """System autonomously requests a new model"""
        request = {
            'model_type': model_type,
            'reason': reason,
            'priority': 'high' if 'critical' in reason.lower() else 'medium',
            'timestamp': 'now'
        }
        self.model_requests.append(request)
        return request
    
    def register_local_model(self, model_info: dict) -> bool:
        """Register a local model provided by user"""
        try:
            model_name = model_info.get('name', 'custom_local')
            self.available_models[model_name] = {
                'type': 'local',
                'path': model_info.get('path'),
                'format': model_info.get('format', 'unknown'),
                'framework': model_info.get('framework', 'unknown'),
                'status': 'available'
            }
            
            if not self.active_model:
                self.active_model = model_name
            
            return True
        except Exception as e:
            print(f"Error registering model: {e}")
            return False
    
    def register_api_model(self, provider: str, api_key: str) -> bool:
        """Register an API-based model"""
        try:
            self.available_models[provider] = {
                'type': 'api',
                'provider': provider,
                'status': 'available'
            }
            
            # Set environment variable
            os.environ[f"{provider.upper()}_API_KEY"] = api_key
            
            if not self.active_model:
                self.active_model = provider
            
            return True
        except Exception as e:
            print(f"Error registering API model: {e}")
            return False
    
    def switch_model(self, model_name: str) -> bool:
        """Switch to a different available model"""
        if model_name in self.available_models:
            self.active_model = model_name
            return True
        return False
    
    def get_model_status(self) -> dict:
        """Get current model configuration status"""
        return {
            'active_model': self.active_model,
            'available_models': list(self.available_models.keys()),
            'model_details': self.available_models,
            'pending_requests': self.model_requests
        }
